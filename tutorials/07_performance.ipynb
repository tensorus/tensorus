{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Tutorial 7 (Enhanced): Performance ‚Äî Latency and Throughput (Ops/sec)\n","\n","We measure time and throughput for key operations on CPU/GPU and compare storage systems (File/Memory/Tensorus)."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install\n","import sys, subprocess, pkgutil\n","for p in ['numpy','torch','matplotlib','seaborn','requests','pandas','psutil']:\n","    if pkgutil.find_loader(p) is None: subprocess.check_call([sys.executable,'-m','pip','install',p])\n","print('‚úÖ Dependencies ready')"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup\n","import time, numpy as np, torch, requests, pandas as pd, psutil, gc\n","import matplotlib.pyplot as plt, seaborn as sns\n","sns.set_theme(style='whitegrid')\n","API='http://127.0.0.1:7860'\n","def server_ok():\n","    try: return requests.get(f'{API}/health', timeout=2).status_code==200\n","    except: return False\n","SERVER=server_ok(); print('üì° Tensorus:', '‚úÖ Connected' if SERVER else '‚ö†Ô∏è Demo Mode')\n","def timeit(fn, n=1):\n","    t0=time.perf_counter()\n","    for _ in range(n): fn()\n","    dt=time.perf_counter()-t0\n","    return dt/n"]},
  {"cell_type":"markdown","metadata":{},"source":["## Operation Benchmarks and Throughput"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sizes=[(1024,1024),(2048,2048),(4096,)]\n","ops=['creation','matmul','elementwise','reduction']\n","def bench(op, sz, device):\n","    def creation(): return torch.randn(*sz, device=device)\n","    def matmul():\n","        if len(sz)<2: a=torch.randn(sz[0],sz[0],device=device); b=torch.randn(sz[0],sz[0],device=device)\n","        else: a=torch.randn(*sz,device=device); b=torch.randn(sz[-1], sz[-2], device=device); return a@b\n","    def elementwise(): a=torch.randn(*sz,device=device); b=torch.randn(*sz,device=device); return a*b+torch.sin(a)-torch.cos(b)\n","    def reduction(): x=torch.randn(*sz,device=device); return x.sum()+x.mean()+x.std()\n","    f={'creation':creation,'matmul':matmul,'elementwise':elementwise,'reduction':reduction}[op]\n","    dt=timeit(f, n=3); th=1.0/dt if dt>0 else float('inf'); return dt*1000, th\n","rows=[]\n","for sz in sizes:\n","    for op in ops:\n","        dt,th=bench(op,sz,'cpu'); rows.append({'size':str(sz),'op':op,'system':'CPU','ms':dt,'ops_per_sec':th})\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache(); dt,th=bench(op,sz,'cuda'); torch.cuda.synchronize(); rows.append({'size':str(sz),'op':op,'system':'GPU','ms':dt,'ops_per_sec':th})\n","df=pd.DataFrame(rows); df.head()"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,4));\n","sns.barplot(data=df, x='op', y='ms', hue='system'); plt.title('Latency (ms) by Operation and System'); plt.show()\n","plt.figure(figsize=(10,4));\n","sns.barplot(data=df, x='op', y='ops_per_sec', hue='system'); plt.title('Throughput (ops/sec) by Operation and System'); plt.show()"]},
  {"cell_type":"markdown","metadata":{},"source":["## Storage Benchmarks (File/Memory/Tensorus)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def bench_tensorus(tensor, n=30):\n","    times=[]\n","    try:\n","        r=requests.post(f'{API}/api/v1/tensors', json={'tensor_data':tensor.tolist()}, timeout=5); tid=r.json().get('tensor_id')\n","        if not tid: return []\n","        for _ in range(n): t0=time.perf_counter(); rr=requests.get(f'{API}/api/v1/tensors/{tid}', timeout=5);\n","        if rr.status_code==200: times.append(time.perf_counter()-t0)\n","        requests.delete(f'{API}/api/v1/tensors/{tid}', timeout=5)\n","    except Exception: return []\n","    return times\n","def bench_file(tensor, n=30):\n","    import tempfile, os\n","    times=[]; path=tempfile.NamedTemporaryFile(delete=False, suffix='.pt').name\n","    torch.save(tensor, path)\n","    for _ in range(n): t0=time.perf_counter(); _=torch.load(path); times.append(time.perf_counter()-t0)\n","    os.unlink(path); return times\n","def bench_memory(tensor, n=30):\n","    t=tensor.clone(); times=[]\n","    for _ in range(n): t0=time.perf_counter(); _=t.clone(); times.append(time.perf_counter()-t0)\n","    return times\n","tensor=torch.randn(1024,1024)\n","file_t=bench_file(tensor); mem_t=bench_memory(tensor); tus_t=bench_tensorus(tensor) if SERVER else []\n","def ms(x): return np.mean(x)*1000 if x else None\n","print('Mean ms ‚Äî File:',ms(file_t),'Memory:',ms(mem_t),'Tensorus:',ms(tus_t))"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
