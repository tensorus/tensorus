{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Tutorial 5: AutoML AGENT ‚Äî End-to-End Optimization\n","\n","This notebook demonstrates the AutoML Agent: dataset creation, hyperparameter optimization, leaderboard, best model summary, and quick inference. Runs in Connected Mode (Tensorus API) or Demo Mode (local simulation)."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lightweight install cell\n","import sys, subprocess, pkgutil\n","for p in ['numpy','torch','matplotlib','seaborn','requests','scikit-learn']:\n","    if pkgutil.find_loader(p) is None:\n","        subprocess.check_call([sys.executable,'-m','pip','install',p])\n","print('‚úÖ Dependencies ready')"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup\n","import time, random, json, requests, numpy as np, torch\n","import matplotlib.pyplot as plt, seaborn as sns\n","from sklearn.datasets import make_classification, make_regression\n","from sklearn.model_selection import train_test_split\n","sns.set_theme(style='whitegrid')\n","API='http://127.0.0.1:7860'\n","def server_ok():\n","    try:\n","        return requests.get(f'{API}/health', timeout=2).status_code==200\n","    except: return False\n","SERVER=server_ok(); print('üì° Tensorus:', '‚úÖ Connected' if SERVER else '‚ö†Ô∏è Demo Mode')"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 1 ‚Äî Prepare Dataset (Classification)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = make_classification(n_samples=1200, n_features=20, n_informative=10, n_redundant=2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n","print('Train:',X_train.shape,'Val:',X_val.shape)"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 2 ‚Äî Define Search Space and Agent Simulation"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["search_space = {\n","  'architectures': ['mlp','deep_mlp','wide_mlp','residual_mlp'],\n","  'hidden_sizes': [(64,), (128,), (256,), (64,32), (128,64), (256,128,64)],\n","  'learning_rates': [0.001, 0.003, 0.01, 0.03],\n","  'batch_sizes': [16,32,64,128],\n","  'optimizers': ['adam','sgd','rmsprop'],\n","  'activations': ['relu','tanh','leaky_relu'],\n","  'dropout_rates': [0.0, 0.1, 0.2, 0.3],\n","  'weight_decay': [0.0, 1e-5, 1e-4]\n","}\n","\n","def score_config(cfg):\n","    # Simulated scoring; higher is better\n","    base=0.70\n","    arch_bonus={'mlp':0.00,'deep_mlp':0.05,'wide_mlp':0.03,'residual_mlp':0.08}[cfg['arch']]\n","    lr=cfg['lr']; lr_bonus=-abs(lr-0.01)*2\n","    depth=len(cfg['hidden']); depth_bonus=min(0.1, depth*0.02)\n","    drop=cfg['drop']; drop_bonus=0.02 if 0.1<=drop<=0.3 else -0.01\n","    noise=np.random.normal(0,0.02)\n","    return float(np.clip(base+arch_bonus+lr_bonus+depth_bonus+drop_bonus+noise,0.5,0.98))\n","\n","def random_cfg():\n","    return {\n","      'arch': random.choice(search_space['architectures']),\n","      'hidden': random.choice(search_space['hidden_sizes']),\n","      'lr': random.choice(search_space['learning_rates']),\n","      'bs': random.choice(search_space['batch_sizes']),\n","      'opt': random.choice(search_space['optimizers']),\n","      'act': random.choice(search_space['activations']),\n","      'drop': random.choice(search_space['dropout_rates']),\n","      'wd': random.choice(search_space['weight_decay'])\n","    }\n","\n","def mutate_cfg(cfg):\n","    new=dict(cfg)\n","    for k in random.sample(list(cfg.keys()), k=min(2,len(cfg))):\n","        if k=='arch': new[k]=random.choice(search_space['architectures'])\n","        elif k=='hidden': new[k]=random.choice(search_space['hidden_sizes'])\n","        elif k=='lr': new[k]=random.choice(search_space['learning_rates'])\n","        elif k=='bs': new[k]=random.choice(search_space['batch_sizes'])\n","        elif k=='opt': new[k]=random.choice(search_space['optimizers'])\n","        elif k=='act': new[k]=random.choice(search_space['activations'])\n","        elif k=='drop': new[k]=random.choice(search_space['dropout_rates'])\n","        elif k=='wd': new[k]=random.choice(search_space['weight_decay'])\n","    return new\n"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 3 ‚Äî Run Optimization (Bayesian-like + Random/Mutate)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trials=40\n","history=[]; best=None\n","for t in range(trials):\n","    if t<5 or (best is None) or random.random()<0.35:\n","        cfg=random_cfg()\n","    else:\n","        cfg=mutate_cfg(best['config'])\n","    sc=score_config(cfg)\n","    rec={'trial':t+1,'score':sc,'config':cfg}\n","    history.append(rec)\n","    if (best is None) or (sc>best['score']): best=rec\n","    if (t+1)%10==0: print('Trial', t+1, '| best=', f"{best['score']:.4f}")\n","print('Best score:',best['score'])\n","# Plot optimization history\n","plt.figure(); plt.plot([h['score'] for h in history], '-o'); plt.xlabel('trial'); plt.ylabel('score'); plt.title('Optimization History'); plt.show()\n","# Leaderboard\n","leader=sorted(history,key=lambda x:x['score'], reverse=True)[:5]\n","for i,rec in enumerate(leader,1):\n","    print(f'{i}. {rec['score']:.4f} | {rec['config']}')"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 4 ‚Äî Quick Inference Demo (Simulated)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Simulated inference: use best config to score validation samples\n","val_scores = np.random.normal(loc=best['score'], scale=0.01, size=10)\n","print('Validation batch scores (simulated):', np.round(val_scores,4))"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
