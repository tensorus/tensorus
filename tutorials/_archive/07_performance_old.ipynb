{
 "cells": [
  {"cell_type":"markdown","metadata":{},"source":["# Tutorial 7: Performance ‚Äî Benchmarks and Analysis\n","\n","Benchmark core tensor operations and storage systems. Runs with live Tensorus API when available, otherwise simulates results."]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lightweight install cell\n","import sys, subprocess, pkgutil\n","for p in ['numpy','torch','matplotlib','seaborn','requests','psutil']:\n","    if pkgutil.find_loader(p) is None:\n","        subprocess.check_call([sys.executable,'-m','pip','install',p])\n","print('‚úÖ Dependencies ready')"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup\n","import time, json, requests, numpy as np, torch, psutil, gc\n","import matplotlib.pyplot as plt, seaborn as sns\n","sns.set_theme(style='whitegrid')\n","API='http://127.0.0.1:7860'\n","def server_ok():\n","    try: return requests.get(f'{API}/health', timeout=2).status_code==200\n","    except: return False\n","SERVER=server_ok(); print('üì° Tensorus:', '‚úÖ Connected' if SERVER else '‚ö†Ô∏è Demo Mode')\n","\n","def timeit(fn):\n","    t0=time.perf_counter(); fn(); dt=time.perf_counter()-t0; return dt\n"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 1 ‚Äî Tensor Operation Benchmarks (CPU/GPU)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sizes=[(1024,1024),(2048,2048),(4096,)]\n","ops=['creation','matmul','elementwise','reduction']\n","results=[]\n","def bench_creation(sz, device):\n","    return torch.randn(*sz, device=device)\n","def bench_matmul(sz, device):\n","    if len(sz)<2: a=torch.randn(sz[0], sz[0], device=device); b=torch.randn(sz[0], sz[0], device=device)\n","    else: a=torch.randn(*sz, device=device); b=torch.randn(sz[-1], sz[-2], device=device)\n","    return a@b\n","def bench_elementwise(sz, device):\n","    a=torch.randn(*sz, device=device); b=torch.randn(*sz, device=device); return a*b + torch.sin(a) - torch.cos(b)\n","def bench_reduction(sz, device):\n","    x=torch.randn(*sz, device=device); return x.sum()+x.mean()+x.std()\n","dispatch={'creation':bench_creation,'matmul':bench_matmul,'elementwise':bench_elementwise,'reduction':bench_reduction}\n","for sz in sizes:\n","    for op in ops:\n","        # CPU\n","        gc.collect(); dt=timeit(lambda: dispatch[op](sz, 'cpu'))\n","        results.append({'size':sz,'op':op,'system':'CPU','ms':dt*1000})\n","        if torch.cuda.is_available():\n","            torch.cuda.empty_cache(); dt=timeit(lambda: dispatch[op](sz, 'cuda'))\n","            torch.cuda.synchronize()\n","            results.append({'size':sz,'op':op,'system':'GPU','ms':dt*1000})\n","print('Samples:', len(results))\n","# Plot\n","import pandas as pd\n","df=pd.DataFrame(results)\n","plt.figure(figsize=(10,5));\n","for op in ops:\n","    sub=df[df.op==op]\n","    for sys in sub.system.unique():\n","        ssub=sub[sub.system==sys]\n","        plt.plot(range(len(ssub)), ssub.ms, '-o', label=f'{op}-{sys}')\n","plt.legend(); plt.ylabel('time (ms)'); plt.title('Operation Benchmarks (ordered by test)'); plt.show()"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 2 ‚Äî Storage Benchmarks (Tensorus vs File vs Memory)"]},
  {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def bench_tensorus(tensor, n=50):\n","    times=[]\n","    try:\n","        r=requests.post(f'{API}/api/v1/tensors', json={'tensor_data': tensor.tolist()}, timeout=5)\n","        tid=r.json().get('tensor_id')\n","        if not tid: return []\n","        for _ in range(n):\n","            t0=time.perf_counter(); rr=requests.get(f'{API}/api/v1/tensors/{tid}', timeout=5);\n","            if rr.status_code==200: times.append(time.perf_counter()-t0)\n","        requests.delete(f'{API}/api/v1/tensors/{tid}', timeout=5)\n","    except Exception as e:\n","        return []\n","    return times\n","\n","def bench_file(tensor, n=50):\n","    import tempfile, os\n","    times=[]\n","    with tempfile.NamedTemporaryFile(delete=False, suffix='.pt') as f:\n","        path=f.name\n","    torch.save(tensor, path)\n","    for _ in range(n):\n","        t0=time.perf_counter(); _=torch.load(path); times.append(time.perf_counter()-t0)\n","    os.unlink(path)\n","    return times\n","\n","def bench_memory(tensor, n=50):\n","    t=tensor.clone(); times=[]\n","    for _ in range(n):\n","        t0=time.perf_counter(); _=t.clone(); times.append(time.perf_counter()-t0)\n","    return times\n","\n","tensor=torch.randn(1024,1024)\n","data_size=tensor.numel()*4\n","file_times=bench_file(tensor, n=40)\n","mem_times=bench_memory(tensor, n=40)\n","tus_times=bench_tensorus(tensor, n=40) if SERVER else []\n","print('Ops collected: file',len(file_times),'mem',len(mem_times),'tensorus',len(tus_times))\n","def ms(x): return np.mean(x)*1000 if x else None\n","print('Mean ms ‚Äî File:',ms(file_times),'Memory:',ms(mem_times),'Tensorus:',ms(tus_times))\n","# Bar chart\n","labels=['File','Memory'] + (['Tensorus'] if tus_times else [])\n","means=[ms(file_times), ms(mem_times)] + ([ms(tus_times)] if tus_times else [])\n","plt.figure(); plt.bar(labels, means, color=['gray','orange','tab:blue'][:len(labels)]); plt.ylabel('ms'); plt.title('Storage Retrieval Mean Latency'); plt.show()"]},
  {"cell_type":"markdown","metadata":{},"source":["## Step 3 ‚Äî Summary and Takeaways"]},
  {"cell_type":"markdown","metadata":{},"source":["- CPU vs GPU differences are highlighted across operations.\n","- File vs Memory vs Tensorus (when connected) showcase storage tradeoffs.\n","- Use these patterns to size workloads and choose the right execution mode."]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
