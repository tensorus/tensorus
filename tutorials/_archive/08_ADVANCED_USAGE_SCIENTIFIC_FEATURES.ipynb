{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Tensorus Tutorial 7: Scientific Features - Track Every Computation\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- **Master** computational lineage and provenance tracking\n",
    "- **Implement** reproducible scientific workflows\n",
    "- **Analyze** complex tensor operations with full traceability\n",
    "- **Optimize** scientific computing pipelines\n",
    "- **Collaborate** on large-scale research projects\n",
    "\n",
    "**â±ï¸ Duration:** 25 minutes | **ðŸŽ“ Level:** Expert\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Scientific Computing Revolution\n",
    "\n",
    "Tensorus brings **unprecedented scientific rigor** to tensor operations with complete computational lineage, reproducibility, and collaboration features.\n",
    "\n",
    "### ðŸ”¬ Scientific Capabilities:\n",
    "\n",
    "| Traditional Computing | **Tensorus Scientific Features** |\n",
    "|----------------------|----------------------------------|\n",
    "| No operation tracking | ðŸ” **Complete computational lineage** |\n",
    "| Manual documentation | ðŸ“ **Automatic metadata capture** |\n",
    "| Irreproducible results | ðŸ”„ **Perfect reproducibility** |\n",
    "| Isolated workflows | ðŸ¤ **Collaborative research** |\n",
    "| Lost intermediate data | ðŸ’¾ **Full operation history** |\n",
    "| Manual error checking | âœ… **Automated validation** |\n",
    "\n",
    "### ðŸŽ¯ Core Scientific Features:\n",
    "\n",
    "1. **ðŸ“Š Computational Lineage** - Track every operation from input to output\n",
    "2. **ðŸ”„ Reproducibility Engine** - Guarantee identical results across runs\n",
    "3. **ðŸ“ Automatic Documentation** - Generate research papers from code\n",
    "4. **ðŸ” Provenance Tracking** - Know exactly how every result was computed\n",
    "5. **ðŸ¤ Collaboration Tools** - Share and version scientific workflows\n",
    "6. **ðŸ“ˆ Performance Analytics** - Optimize computational efficiency\n",
    "7. **âœ… Validation Framework** - Ensure scientific correctness\n",
    "8. **ðŸŒ Integration APIs** - Connect with scientific tools (NumPy, SciPy, etc.)\n",
    "\n",
    "### ðŸ† Research Impact:\n",
    "- **ðŸŽ“ Publications**: Auto-generate methods sections\n",
    "- **ðŸ”¬ Peer Review**: Provide complete computational transparency\n",
    "- **ðŸ¤ Collaboration**: Share exact workflows with colleagues\n",
    "- **ðŸ“Š Funding**: Demonstrate computational rigor to agencies\n",
    "\n",
    "**ðŸŒŸ Result: The most advanced scientific tensor computing platform!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ› ï¸ Setup: Advanced Scientific Computing Framework\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime, timezone\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, deque\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style for scientific plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "class OperationType(Enum):\n",
    "    \"\"\"Types of tensor operations for lineage tracking\"\"\"\n",
    "    CREATION = \"creation\"\n",
    "    ARITHMETIC = \"arithmetic\"\n",
    "    LINEAR_ALGEBRA = \"linear_algebra\"\n",
    "    DECOMPOSITION = \"decomposition\"\n",
    "    TRANSFORMATION = \"transformation\"\n",
    "    REDUCTION = \"reduction\"\n",
    "    INDEXING = \"indexing\"\n",
    "    ANALYSIS = \"analysis\"\n",
    "\n",
    "@dataclass\n",
    "class ComputationalNode:\n",
    "    \"\"\"Node in computational lineage graph\"\"\"\n",
    "    node_id: str\n",
    "    operation_type: OperationType\n",
    "    operation_name: str\n",
    "    parameters: Dict[str, Any]\n",
    "    input_tensors: List[str]\n",
    "    output_tensors: List[str]\n",
    "    timestamp: datetime\n",
    "    execution_time: float\n",
    "    memory_usage: int\n",
    "    researcher: str\n",
    "    environment: Dict[str, str]\n",
    "    checksum: str = \"\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.checksum:\n",
    "            self.checksum = self._compute_checksum()\n",
    "    \n",
    "    def _compute_checksum(self) -> str:\n",
    "        \"\"\"Compute reproducibility checksum\"\"\"\n",
    "        data = f\"{self.operation_name}_{self.parameters}_{self.input_tensors}\"\n",
    "        return hashlib.sha256(data.encode()).hexdigest()[:16]\n",
    "\n",
    "@dataclass\n",
    "class ScientificTensor:\n",
    "    \"\"\"Tensor with complete scientific metadata\"\"\"\n",
    "    tensor_id: str\n",
    "    data: torch.Tensor\n",
    "    shape: Tuple[int, ...]\n",
    "    dtype: torch.dtype\n",
    "    creation_node: str\n",
    "    lineage_depth: int\n",
    "    physical_units: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    quality_metrics: Dict[str, float] = field(default_factory=dict)\n",
    "    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.tensor_id:\n",
    "            self.tensor_id = str(uuid.uuid4())[:8]\n",
    "        self.shape = tuple(self.data.shape)\n",
    "        self.dtype = self.data.dtype\n",
    "\n",
    "class ScientificComputing:\n",
    "    \"\"\"Advanced scientific computing framework with full lineage tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, researcher_name: str = \"Scientist\", api_url: str = \"http://127.0.0.1:7860\"):\n",
    "        self.researcher_name = researcher_name\n",
    "        self.api_url = api_url\n",
    "        self.server_available = self._test_connection()\n",
    "        \n",
    "        # Scientific tracking\n",
    "        self.lineage_graph = nx.DiGraph()\n",
    "        self.tensors: Dict[str, ScientificTensor] = {}\n",
    "        self.operations: Dict[str, ComputationalNode] = {}\n",
    "        self.session_id = str(uuid.uuid4())[:8]\n",
    "        self.experiment_metadata = {\n",
    "            \"session_id\": self.session_id,\n",
    "            \"researcher\": researcher_name,\n",
    "            \"start_time\": datetime.now(timezone.utc),\n",
    "            \"environment\": self._get_environment_info()\n",
    "        }\n",
    "        \n",
    "        print(f\"ðŸ”¬ Scientific Computing Session Started\")\n",
    "        print(f\"ðŸ‘¨â€ðŸ”¬ Researcher: {researcher_name}\")\n",
    "        print(f\"ðŸ†” Session ID: {self.session_id}\")\n",
    "        print(f\"ðŸ“¡ Tensorus: {'âœ… Connected' if self.server_available else 'âš ï¸ Local Mode'}\")\n",
    "    \n",
    "    def _test_connection(self) -> bool:\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_url}/health\", timeout=3)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def _get_environment_info(self) -> Dict[str, str]:\n",
    "        \"\"\"Capture environment for reproducibility\"\"\"\n",
    "        return {\n",
    "            \"python_version\": f\"{torch.__version__}\",\n",
    "            \"pytorch_version\": torch.__version__,\n",
    "            \"numpy_version\": np.__version__,\n",
    "            \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "        }\n",
    "    \n",
    "    def create_tensor(self, \n",
    "                     data: Union[torch.Tensor, np.ndarray, List], \n",
    "                     description: str = \"\",\n",
    "                     units: Optional[str] = None,\n",
    "                     tags: List[str] = None) -> ScientificTensor:\n",
    "        \"\"\"Create a scientifically tracked tensor\"\"\"\n",
    "        \n",
    "        # Convert to tensor if needed\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        # Create operation node\n",
    "        node_id = f\"create_{len(self.operations):04d}\"\n",
    "        tensor_id = f\"tensor_{len(self.tensors):04d}\"\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Create computational node\n",
    "        operation = ComputationalNode(\n",
    "            node_id=node_id,\n",
    "            operation_type=OperationType.CREATION,\n",
    "            operation_name=\"create_tensor\",\n",
    "            parameters={\n",
    "                \"shape\": list(data.shape),\n",
    "                \"dtype\": str(data.dtype),\n",
    "                \"description\": description,\n",
    "                \"units\": units\n",
    "            },\n",
    "            input_tensors=[],\n",
    "            output_tensors=[tensor_id],\n",
    "            timestamp=datetime.now(timezone.utc),\n",
    "            execution_time=time.perf_counter() - start_time,\n",
    "            memory_usage=data.numel() * data.element_size(),\n",
    "            researcher=self.researcher_name,\n",
    "            environment=self.experiment_metadata[\"environment\"]\n",
    "        )\n",
    "        \n",
    "        # Create scientific tensor\n",
    "        scientific_tensor = ScientificTensor(\n",
    "            tensor_id=tensor_id,\n",
    "            data=data,\n",
    "            shape=tuple(data.shape),\n",
    "            dtype=data.dtype,\n",
    "            creation_node=node_id,\n",
    "            lineage_depth=0,\n",
    "            physical_units=units,\n",
    "            description=description,\n",
    "            tags=tags or [],\n",
    "            quality_metrics=self._compute_quality_metrics(data)\n",
    "        )\n",
    "        \n",
    "        # Store in tracking systems\n",
    "        self.operations[node_id] = operation\n",
    "        self.tensors[tensor_id] = scientific_tensor\n",
    "        self.lineage_graph.add_node(node_id, **asdict(operation))\n",
    "        \n",
    "        # Store in Tensorus if available\n",
    "        if self.server_available:\n",
    "            self._store_in_tensorus(scientific_tensor, operation)\n",
    "        \n",
    "        print(f\"ðŸ“Š Created tensor {tensor_id}: {data.shape} {data.dtype}\")\n",
    "        if description:\n",
    "            print(f\"   ðŸ“ Description: {description}\")\n",
    "        if units:\n",
    "            print(f\"   ðŸ“ Units: {units}\")\n",
    "        \n",
    "        return scientific_tensor\n",
    "    \n",
    "    def _compute_quality_metrics(self, tensor: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"Compute quality metrics for scientific validation\"\"\"\n",
    "        with torch.no_grad():\n",
    "            metrics = {\n",
    "                \"mean\": tensor.mean().item(),\n",
    "                \"std\": tensor.std().item(),\n",
    "                \"min\": tensor.min().item(),\n",
    "                \"max\": tensor.max().item(),\n",
    "                \"norm\": torch.norm(tensor).item(),\n",
    "                \"sparsity\": (tensor == 0).float().mean().item()\n",
    "            }\n",
    "            \n",
    "            # Add matrix-specific metrics\n",
    "            if tensor.ndim == 2 and tensor.shape[0] == tensor.shape[1]:\n",
    "                try:\n",
    "                    eigenvals = torch.linalg.eigvals(tensor)\n",
    "                    metrics[\"condition_number\"] = (eigenvals.real.max() / eigenvals.real.min()).item()\n",
    "                    metrics[\"determinant\"] = torch.linalg.det(tensor).item()\n",
    "                    metrics[\"trace\"] = torch.trace(tensor).item()\n",
    "                except:\n",
    "                    pass  # Skip if computation fails\n",
    "            \n",
    "            return metrics\n",
    "    \n",
    "    def scientific_operation(self, \n",
    "                           operation_name: str,\n",
    "                           operation_type: OperationType,\n",
    "                           input_tensors: List[ScientificTensor],\n",
    "                           operation_func: Callable,\n",
    "                           parameters: Dict[str, Any] = None,\n",
    "                           description: str = \"\") -> ScientificTensor:\n",
    "        \"\"\"Execute a scientifically tracked operation\"\"\"\n",
    "        \n",
    "        parameters = parameters or {}\n",
    "        node_id = f\"{operation_name}_{len(self.operations):04d}\"\n",
    "        tensor_id = f\"tensor_{len(self.tensors):04d}\"\n",
    "        \n",
    "        print(f\"\\nðŸ”¬ Executing: {operation_name}\")\n",
    "        print(f\"   ðŸ“¥ Inputs: {[t.tensor_id for t in input_tensors]}\")\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Execute operation\n",
    "        try:\n",
    "            input_data = [t.data for t in input_tensors]\n",
    "            result_data = operation_func(*input_data, **parameters)\n",
    "            \n",
    "            if not isinstance(result_data, torch.Tensor):\n",
    "                result_data = torch.tensor(result_data, dtype=torch.float32)\n",
    "            \n",
    "            execution_time = time.perf_counter() - start_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Operation failed: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Create operation node\n",
    "        operation = ComputationalNode(\n",
    "            node_id=node_id,\n",
    "            operation_type=operation_type,\n",
    "            operation_name=operation_name,\n",
    "            parameters=parameters,\n",
    "            input_tensors=[t.tensor_id for t in input_tensors],\n",
    "            output_tensors=[tensor_id],\n",
    "            timestamp=datetime.now(timezone.utc),\n",
    "            execution_time=execution_time,\n",
    "            memory_usage=result_data.numel() * result_data.element_size(),\n",
    "            researcher=self.researcher_name,\n",
    "            environment=self.experiment_metadata[\"environment\"]\n",
    "        )\n",
    "        \n",
    "        # Determine lineage depth\n",
    "        max_input_depth = max([t.lineage_depth for t in input_tensors], default=-1)\n",
    "        \n",
    "        # Create result tensor\n",
    "        result_tensor = ScientificTensor(\n",
    "            tensor_id=tensor_id,\n",
    "            data=result_data,\n",
    "            shape=tuple(result_data.shape),\n",
    "            dtype=result_data.dtype,\n",
    "            creation_node=node_id,\n",
    "            lineage_depth=max_input_depth + 1,\n",
    "            description=description,\n",
    "            quality_metrics=self._compute_quality_metrics(result_data)\n",
    "        )\n",
    "        \n",
    "        # Update tracking systems\n",
    "        self.operations[node_id] = operation\n",
    "        self.tensors[tensor_id] = result_tensor\n",
    "        \n",
    "        # Add to lineage graph\n",
    "        self.lineage_graph.add_node(node_id, **asdict(operation))\n",
    "        for input_tensor in input_tensors:\n",
    "            self.lineage_graph.add_edge(input_tensor.creation_node, node_id)\n",
    "        \n",
    "        # Store in Tensorus if available\n",
    "        if self.server_available:\n",
    "            self._store_in_tensorus(result_tensor, operation)\n",
    "        \n",
    "        print(f\"   ðŸ“¤ Output: {tensor_id} {result_data.shape} {result_data.dtype}\")\n",
    "        print(f\"   â±ï¸  Time: {execution_time*1000:.2f}ms\")\n",
    "        print(f\"   ðŸ“Š Lineage depth: {result_tensor.lineage_depth}\")\n",
    "        \n",
    "        return result_tensor\n",
    "    \n",
    "    def _store_in_tensorus(self, tensor: ScientificTensor, operation: ComputationalNode):\n",
    "        \"\"\"Store tensor and operation in Tensorus for persistence\"\"\"\n",
    "        try:\n",
    "            payload = {\n",
    "                \"tensor_data\": tensor.data.tolist(),\n",
    "                \"metadata\": {\n",
    "                    \"tensor_id\": tensor.tensor_id,\n",
    "                    \"scientific_metadata\": asdict(tensor),\n",
    "                    \"operation_metadata\": asdict(operation),\n",
    "                    \"session_id\": self.session_id,\n",
    "                    \"researcher\": self.researcher_name\n",
    "                }\n",
    "            }\n",
    "            requests.post(f\"{self.api_url}/api/v1/scientific/tensors\", json=payload)\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ Failed to store in Tensorus: {e}\")\n",
    "    \n",
    "    def matrix_multiply(self, a: ScientificTensor, b: ScientificTensor, \n",
    "                       description: str = \"Matrix multiplication\") -> ScientificTensor:\n",
    "        \"\"\"Scientifically tracked matrix multiplication\"\"\"\n",
    "        return self.scientific_operation(\n",
    "            operation_name=\"matrix_multiply\",\n",
    "            operation_type=OperationType.LINEAR_ALGEBRA,\n",
    "            input_tensors=[a, b],\n",
    "            operation_func=torch.matmul,\n",
    "            description=description\n",
    "        )\n",
    "    \n",
    "    def tensor_decomposition(self, tensor: ScientificTensor, method: str = \"svd\",\n",
    "                           description: str = \"Tensor decomposition\") -> List[ScientificTensor]:\n",
    "        \"\"\"Scientifically tracked tensor decomposition\"\"\"\n",
    "        \n",
    "        def svd_operation(x):\n",
    "            U, S, Vt = torch.linalg.svd(x)\n",
    "            return [U, S, Vt]\n",
    "        \n",
    "        # For simplicity, return first component\n",
    "        # In practice, this would return multiple tensors\n",
    "        def svd_first_component(x):\n",
    "            U, S, Vt = torch.linalg.svd(x)\n",
    "            return U\n",
    "        \n",
    "        return self.scientific_operation(\n",
    "            operation_name=f\"decomposition_{method}\",\n",
    "            operation_type=OperationType.DECOMPOSITION,\n",
    "            input_tensors=[tensor],\n",
    "            operation_func=svd_first_component,\n",
    "            parameters={\"method\": method},\n",
    "            description=description\n",
    "        )\n",
    "    \n",
    "    def element_wise_operation(self, a: ScientificTensor, b: ScientificTensor, \n",
    "                             operation: str = \"add\",\n",
    "                             description: str = \"\") -> ScientificTensor:\n",
    "        \"\"\"Scientifically tracked element-wise operations\"\"\"\n",
    "        \n",
    "        ops = {\n",
    "            \"add\": torch.add,\n",
    "            \"subtract\": torch.subtract,\n",
    "            \"multiply\": torch.multiply,\n",
    "            \"divide\": torch.divide\n",
    "        }\n",
    "        \n",
    "        if operation not in ops:\n",
    "            raise ValueError(f\"Unknown operation: {operation}\")\n",
    "        \n",
    "        return self.scientific_operation(\n",
    "            operation_name=f\"element_wise_{operation}\",\n",
    "            operation_type=OperationType.ARITHMETIC,\n",
    "            input_tensors=[a, b],\n",
    "            operation_func=ops[operation],\n",
    "            parameters={\"operation\": operation},\n",
    "            description=description or f\"Element-wise {operation}\"\n",
    "        )\n",
    "    \n",
    "    def get_lineage_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive lineage summary\"\"\"\n",
    "        return {\n",
    "            \"session_id\": self.session_id,\n",
    "            \"researcher\": self.researcher_name,\n",
    "            \"total_tensors\": len(self.tensors),\n",
    "            \"total_operations\": len(self.operations),\n",
    "            \"max_lineage_depth\": max([t.lineage_depth for t in self.tensors.values()], default=0),\n",
    "            \"operation_types\": dict(defaultdict(int, {\n",
    "                op_type.value: sum(1 for op in self.operations.values() if op.operation_type == op_type)\n",
    "                for op_type in OperationType\n",
    "            })),\n",
    "            \"total_execution_time\": sum(op.execution_time for op in self.operations.values()),\n",
    "            \"total_memory_usage\": sum(op.memory_usage for op in self.operations.values())\n",
    "        }\n",
    "\n",
    "# Initialize scientific computing framework\n",
    "print(\"ðŸ”¬ SCIENTIFIC FEATURES TUTORIAL\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ðŸŽ¯ Today: Master computational lineage and reproducibility!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {"name": "ipython", "version": 3},
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
