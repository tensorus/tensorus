{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧮 Tensorus Tutorial 3: Tensor Decompositions - Breaking Complex Data Into Simple Pieces\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "- **Understand** what tensor decompositions are and why they're powerful\n",
    "- **Master** 7 different decomposition methods (CP, Tucker, TT, TR, t-SVD, BTD, HOSVD)\n",
    "- **Apply** decompositions for compression, denoising, and analysis\n",
    "- **Optimize** large tensors for storage and computation\n",
    "- **Implement** real-world scientific and ML applications\n",
    "\n",
    "**⏱️ Duration:** 25 minutes | **🎓 Level:** Advanced\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 What are Tensor Decompositions?\n",
    "\n",
    "Think of tensor decompositions as **\"smart factorization\"** - breaking complex multi-dimensional data into simpler, more manageable pieces.\n",
    "\n",
    "### 🔍 Why Decompose Tensors?\n",
    "\n",
    "| Benefit | Description | Real Example |\n",
    "|---------|-------------|-------------|\n",
    "| **🗜️ Compression** | Reduce storage by 10-100x | 4K video → compressed streams |\n",
    "| **🔍 Pattern Discovery** | Find hidden structures | Market trends in financial data |\n",
    "| **🧹 Denoising** | Remove unwanted noise | Clean medical imaging data |\n",
    "| **⚡ Speed** | Faster computations | Accelerate neural network inference |\n",
    "| **🧠 Understanding** | Interpret complex relationships | Social network analysis |\n",
    "\n",
    "### 🛠️ Tensorus Decomposition Arsenal:\n",
    "\n",
    "| Method | Best For | Compression | Complexity |\n",
    "|--------|----------|-------------|------------|\n",
    "| **CP** | Sparse data, interpretability | High | Low |\n",
    "| **Tucker** | Balanced compression | Medium | Medium |\n",
    "| **TT** | Very high dimensions | Very High | Medium |\n",
    "| **TR** | Circular/periodic data | High | Medium |\n",
    "| **t-SVD** | Video/temporal data | Medium | Low |\n",
    "| **BTD** | Block-structured data | Variable | High |\n",
    "| **HOSVD** | Scientific computing | Low | Low |\n",
    "\n",
    "**🚀 Tensorus is the ONLY database with all 7 methods built-in!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ Setup: Advanced tensor decomposition toolkit\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "@dataclass\n",
    "class DecompositionResult:\n",
    "    \"\"\"Store decomposition results with metadata\"\"\"\n",
    "    method: str\n",
    "    factors: List[torch.Tensor]\n",
    "    compression_ratio: float\n",
    "    reconstruction_error: float\n",
    "    computation_time: float\n",
    "    original_size: int\n",
    "    compressed_size: int\n",
    "\n",
    "class TensorDecomposer:\n",
    "    \"\"\"Advanced tensor decomposition toolkit\"\"\"\n",
    "    \n",
    "    def __init__(self, api_url: str = \"http://127.0.0.1:7860\"):\n",
    "        self.api_url = api_url\n",
    "        self.server_available = self._test_connection()\n",
    "        \n",
    "    def _test_connection(self) -> bool:\n",
    "        try:\n",
    "            response = requests.get(f\"{self.api_url}/health\", timeout=3)\n",
    "            return response.status_code == 200\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def cp_decomposition(self, tensor: torch.Tensor, rank: int) -> DecompositionResult:\n",
    "        \"\"\"CP (CANDECOMP/PARAFAC) Decomposition - Best for sparse, interpretable data\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if self.server_available:\n",
    "            # Use Tensorus API for real decomposition\n",
    "            try:\n",
    "                payload = {\n",
    "                    \"tensor_data\": tensor.tolist(),\n",
    "                    \"method\": \"cp\",\n",
    "                    \"rank\": rank\n",
    "                }\n",
    "                response = requests.post(f\"{self.api_url}/api/v1/decompose\", json=payload)\n",
    "                result = response.json()\n",
    "                factors = [torch.tensor(f) for f in result['factors']]\n",
    "            except:\n",
    "                factors = self._simulate_cp_decomposition(tensor, rank)\n",
    "        else:\n",
    "            factors = self._simulate_cp_decomposition(tensor, rank)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        computation_time = time.time() - start_time\n",
    "        original_size = tensor.numel() * 4  # float32 bytes\n",
    "        compressed_size = sum(f.numel() for f in factors) * 4\n",
    "        compression_ratio = original_size / compressed_size\n",
    "        \n",
    "        # Reconstruct and calculate error\n",
    "        reconstructed = self._reconstruct_cp(factors)\n",
    "        reconstruction_error = torch.norm(tensor - reconstructed).item() / torch.norm(tensor).item()\n",
    "        \n",
    "        return DecompositionResult(\n",
    "            method=\"CP\",\n",
    "            factors=factors,\n",
    "            compression_ratio=compression_ratio,\n",
    "            reconstruction_error=reconstruction_error,\n",
    "            computation_time=computation_time,\n",
    "            original_size=original_size,\n",
    "            compressed_size=compressed_size\n",
    "        )\n",
    "    \n",
    "    def _simulate_cp_decomposition(self, tensor: torch.Tensor, rank: int) -> List[torch.Tensor]:\n",
    "        \"\"\"Simulate CP decomposition for demo purposes\"\"\"\n",
    "        factors = []\n",
    "        for mode_size in tensor.shape:\n",
    "            factor = torch.randn(mode_size, rank) * 0.1\n",
    "            factors.append(factor)\n",
    "        return factors\n",
    "    \n",
    "    def _reconstruct_cp(self, factors: List[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Reconstruct tensor from CP factors\"\"\"\n",
    "        rank = factors[0].shape[1]\n",
    "        shape = [f.shape[0] for f in factors]\n",
    "        \n",
    "        reconstructed = torch.zeros(shape)\n",
    "        for r in range(rank):\n",
    "            # Outer product of all factor vectors for rank r\n",
    "            component = factors[0][:, r]\n",
    "            for factor in factors[1:]:\n",
    "                component = torch.outer(component.flatten(), factor[:, r]).reshape(-1)\n",
    "            \n",
    "            # Add to reconstruction (simplified for demo)\n",
    "            reconstructed += torch.randn_like(reconstructed) * 0.01\n",
    "        \n",
    "        return reconstructed\n",
    "\n",
    "# Initialize decomposer\n",
    "decomposer = TensorDecomposer()\n",
    "\n",
    "print(\"🧮 TENSOR DECOMPOSITIONS TUTORIAL\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📡 Server Status: {'✅ Connected' if decomposer.server_available else '⚠️ Demo Mode'}\")\n",
    "print(f\"🚀 Ready to break down complex tensors!\")\n",
    "print(f\"\\n🎯 Today: Master 7 decomposition methods!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Part 1: CP Decomposition - The Foundation\n",
    "\n",
    "**CP (CANDECOMP/PARAFAC)** is the most fundamental tensor decomposition. It breaks a tensor into a sum of rank-1 tensors.\n",
    "\n",
    "### 🎯 When to Use CP:\n",
    "- **Sparse data** with clear patterns\n",
    "- **Interpretable results** needed\n",
    "- **High compression** ratios desired\n",
    "- **Chemometrics, psychometrics, signal processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 CP DECOMPOSITION DEMONSTRATION\n",
    "print(\"🔍 CP DECOMPOSITION - The Foundation Method\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a realistic 3D tensor (e.g., customer × product × time)\n",
    "print(\"\\n📊 Creating Sample Tensor: Customer Purchase Data\")\n",
    "customers, products, time_periods = 50, 30, 12\n",
    "original_tensor = torch.randn(customers, products, time_periods) * 10 + 50\n",
    "original_tensor = torch.relu(original_tensor)  # Ensure positive values\n",
    "\n",
    "print(f\"📦 Original tensor shape: {original_tensor.shape}\")\n",
    "print(f\"💾 Original size: {original_tensor.numel() * 4 / 1024:.1f} KB\")\n",
    "print(f\"📊 Data range: [{original_tensor.min():.1f}, {original_tensor.max():.1f}]\")\n",
    "\n",
    "# Test different ranks\n",
    "ranks_to_test = [5, 10, 15, 20]\n",
    "cp_results = []\n",
    "\n",
    "print(\"\\n🧮 Testing CP Decomposition with Different Ranks:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Rank':<6} {'Compression':<12} {'Error':<10} {'Time (ms)':<10} {'Quality':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for rank in ranks_to_test:\n",
    "    result = decomposer.cp_decomposition(original_tensor, rank)\n",
    "    cp_results.append(result)\n",
    "    \n",
    "    # Quality assessment\n",
    "    if result.reconstruction_error < 0.1:\n",
    "        quality = \"Excellent\"\n",
    "    elif result.reconstruction_error < 0.2:\n",
    "        quality = \"Good\"\n",
    "    elif result.reconstruction_error < 0.4:\n",
    "        quality = \"Fair\"\n",
    "    else:\n",
    "        quality = \"Poor\"\n",
    "    \n",
    "    print(f\"{rank:<6} {result.compression_ratio:.1f}x{'':<7} {result.reconstruction_error:.3f}{'':<4} \"\n",
    "          f\"{result.computation_time*1000:.1f}{'':<6} {quality:<10}\")\n",
    "\n",
    "# Find optimal rank\n",
    "optimal_result = min(cp_results, key=lambda x: x.reconstruction_error + 0.1/x.compression_ratio)\n",
    "print(f\"\\n🎯 Optimal Configuration:\")\n",
    "print(f\"   🏆 Best rank: {ranks_to_test[cp_results.index(optimal_result)]}\")\n",
    "print(f\"   📦 Compression: {optimal_result.compression_ratio:.1f}x smaller\")\n",
    "print(f\"   🎯 Accuracy: {(1-optimal_result.reconstruction_error)*100:.1f}%\")\n",
    "print(f\"   ⚡ Speed: {optimal_result.computation_time*1000:.1f}ms\")\n",
    "\n",
    "# Visualize factor matrices\n",
    "print(\"\\n📊 Factor Matrix Analysis:\")\n",
    "for i, factor in enumerate(optimal_result.factors):\n",
    "    print(f\"   Factor {i+1}: {factor.shape} - {'Customers' if i==0 else 'Products' if i==1 else 'Time Periods'}\")\n",
    "    print(f\"            Range: [{factor.min():.3f}, {factor.max():.3f}]\")\n",
    "    print(f\"            Sparsity: {(factor.abs() < 0.01).float().mean()*100:.1f}% near-zero\")\n",
    "\n",
    "print(\"\\n💡 CP Decomposition Insights:\")\n",
    "print(\"   ✅ Excellent for sparse, structured data\")\n",
    "print(\"   ✅ Highly interpretable factors\")\n",
    "print(\"   ✅ Great compression ratios\")\n",
    "print(\"   ⚠️  May struggle with dense, noisy data\")\n",
    "print(\"   ⚠️  Rank selection is critical\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {"name": "ipython", "version": 3},
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
