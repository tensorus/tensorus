{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5 (Enhanced): AutoML AGENT ‚Äî Classification + Regression\n",
    "\n",
    "End-to-end optimization with a simulated search strategy. Includes:\n",
    "- Classification dataset\n",
    "- Regression dataset\n",
    "- Search history and leaderboard\n",
    "- Best config summary and quick inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install\n",
    "import sys, subprocess, pkgutil\n",
    "for p in ['numpy','torch','matplotlib','seaborn','requests','scikit-learn','pandas']:\n",
    "    if pkgutil.find_loader(p) is None: subprocess.check_call([sys.executable,'-m','pip','install',p])\n",
    "print('‚úÖ Dependencies ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78253eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import (\n",
    "    ping_server,\n",
    "    ensure_dataset,\n",
    "    ingest_tensor,\n",
    "    fetch_dataset,\n",
    "    summarize_records,\n",
    "    tensor_addition,\n",
    "    pretty_json,\n",
    ")\n",
    "API = \"http://127.0.0.1:7860\"\n",
    "SERVER = ping_server(API)\n",
    "print(f\"üì° Tensorus server available: {SERVER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import random, numpy as np, pandas as pd, requests\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set_theme(style='whitegrid')\n",
    "API='http://127.0.0.1:7860'\n",
    "def server_ok():\n",
    "    try: return requests.get(f'{API}/health', timeout=2).status_code==200\n",
    "    except: return False\n",
    "SERVER=server_ok(); print('üì° Tensorus:', '‚úÖ Connected' if SERVER else '‚ö†Ô∏è Demo Mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A ‚Äî Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_classification(n_samples=1500, n_features=24, n_informative=10, random_state=7)\n",
    "Xtr,Xva,ytr,yva=train_test_split(X,y,test_size=0.25,random_state=7)\n",
    "space={\n",
    "  'arch':['mlp','deep_mlp','wide_mlp','residual_mlp'],\n",
    "  'hidden':[(64,),(128,),(256,),(128,64),(256,128,64)],\n",
    "  'lr':[0.001,0.003,0.01,0.03],\n",
    "  'bs':[16,32,64,128],\n",
    "  'drop':[0.0,0.1,0.2,0.3]\n",
    "}\n",
    "def score(cfg):\n",
    "    base=0.72; arch={'mlp':0.0,'deep_mlp':0.05,'wide_mlp':0.03,'residual_mlp':0.08}[cfg['arch']]\n",
    "    lr_bonus=-abs(cfg['lr']-0.01)*2; depth=len(cfg['hidden'])*0.015; drop=0.02 if 0.1<=cfg['drop']<=0.3 else -0.01\n",
    "    return float(np.clip(base+arch+lr_bonus+depth+drop+np.random.normal(0,0.02),0.5,0.99))\n",
    "def rand_cfg():\n",
    "    return {'arch':random.choice(space['arch']),'hidden':random.choice(space['hidden']),'lr':random.choice(space['lr']),'bs':random.choice(space['bs']),'drop':random.choice(space['drop'])}\n",
    "def mutate(cfg):\n",
    "    c=dict(cfg); k=random.choice(list(c.keys()));\n",
    "    if k in space: c[k]=random.choice(space[k]); return c\n",
    "    return rand_cfg()\n",
    "hist=[]; best=None\n",
    "for t in range(40):\n",
    "    cfg=rand_cfg() if (best is None or t<5 or np.random.rand()<0.35) else mutate(best['config'])\n",
    "    sc=score(cfg); rec={'trial':t+1,'score':sc,'config':cfg}; hist.append(rec)\n",
    "    if (best is None) or sc>best['score']: best=rec\n",
    "print('Best (classification):', best['score'])\n",
    "plt.figure(); plt.plot([h['score'] for h in hist],'-o'); plt.title('Classification Optimization'); plt.show()\n",
    "pd.DataFrame(sorted(hist,key=lambda x:x['score'],reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B ‚Äî Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_regression(n_samples=1200, n_features=16, noise=7.5, random_state=11)\n",
    "Xtr,Xva,ytr,yva=train_test_split(X,y,test_size=0.25,random_state=11)\n",
    "space_r={'hidden':[(64,),(128,64),(256,128,64)],'lr':[0.001,0.003,0.01,0.03],'bs':[16,32,64,128],'drop':[0.0,0.1,0.2]}\n",
    "def rscore(cfg):\n",
    "    base=0.65; depth=len(cfg['hidden'])*0.02; lr=-abs(cfg['lr']-0.003)*1.5; drop=(0.02 if cfg['drop']<=0.2 else -0.01)\n",
    "    return float(np.clip(base+depth+lr+drop+np.random.normal(0,0.02),0.45,0.97))\n",
    "def rrand(): return {'hidden':random.choice(space_r['hidden']),'lr':random.choice(space_r['lr']),'bs':random.choice(space_r['bs']),'drop':random.choice(space_r['drop'])}\n",
    "def rmut(cfg):\n",
    "    c=dict(cfg); k=random.choice(list(c.keys())); c[k]=random.choice(space_r[k]); return c\n",
    "hist_r=[]; best_r=None\n",
    "for t in range(35):\n",
    "    cfg=rrand() if (best_r is None or t<5 or np.random.rand()<0.35) else rmut(best_r['config'])\n",
    "    sc=rscore(cfg); rec={'trial':t+1,'score':sc,'config':cfg}; hist_r.append(rec)\n",
    "    if (best_r is None) or sc>best_r['score']: best_r=rec\n",
    "print('Best (regression):', best_r['score'])\n",
    "plt.figure(); plt.plot([h['score'] for h in hist_r],'-o',color='orange'); plt.title('Regression Optimization'); plt.show()\n",
    "pd.DataFrame(sorted(hist_r,key=lambda x:x['score'],reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Inference (Simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores_cls = np.random.normal(loc=best['score'], scale=0.01, size=10)\n",
    "val_scores_reg = np.random.normal(loc=best_r['score'], scale=0.01, size=10)\n",
    "print('Validation scores (classification):', np.round(val_scores_cls,4))\n",
    "print('Validation scores (regression):', np.round(val_scores_reg,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
