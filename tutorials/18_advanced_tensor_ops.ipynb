{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 18: Advanced Tensor Operations & Workflows\n",
    "\n",
    "Learn how to:\n",
    "- Chain multiple `TensorOps` functions\n",
    "- Use storage-connected operations for cached results\n",
    "- Execute tensor workflows via `/api/v1/vector/tensor-workflow`\n",
    "\n",
    "Demo payloads are generated when the API is offline." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_utils import ping_server, ensure_dataset, ingest_tensor, pretty_json\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "API = 'http://127.0.0.1:7860'\n",
    "SERVER = ping_server(API)\n",
    "print(f'\ud83d\udce1 Tensorus server available: {SERVER}')\n",
    "\n",
    "DATASET = 'tensor_ops_demo'\n",
    "if SERVER:\n",
    "    ensure_dataset(DATASET, API)\n",
    "\n",
    "tensor_a = np.random.rand(32, 32).astype('float32')\n",
    "tensor_b = np.random.rand(32, 32).astype('float32')\n",
    "\n",
    "if SERVER:\n",
    "    result_a = ingest_tensor(DATASET, tensor_a, {'name': 'A'}, API)\n",
    "    result_b = ingest_tensor(DATASET, tensor_b, {'name': 'B'}, API)\n",
    "else:\n",
    "    result_a = {'demo_mode': True, 'record_id': 'A'}\n",
    "    result_b = {'demo_mode': True, 'record_id': 'B'}\n",
    "\n",
    "print('Tensor A insert:', pretty_json(result_a))\n",
    "print('Tensor B insert:', pretty_json(result_b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage-connected addition\n",
    "Demonstrates `/ops/add` with record IDs." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SERVER:\n",
    "    payload = {\n",
    "        'input1': {'dataset_name': DATASET, 'record_id': result_a.get('record_id', 'A')},\n",
    "        'input2': {'dataset_name': DATASET, 'record_id': result_b.get('record_id', 'B')}\n",
    "    }\n",
    "    try:\n",
    "        add_resp = requests.post(f"{API}/ops/add", json=payload, timeout=20)\n",
    "        add_resp.raise_for_status()\n",
    "        add_result = add_resp.json()\n",
    "    except requests.RequestException as exc:\n",
    "        add_result = {'error': str(exc), 'demo_mode': True}\n",
    "else:\n",
    "    add_result = {'demo_mode': True, 'result_record_id': 'sum_AB'}\n",
    "\n",
    "print(pretty_json(add_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor workflow execution\n",
    "Trigger a workflow that normalizes, multiplies, and computes a trace." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_payload = {\n",
    "    'workflow_query': 'Normalize tensors and compute trace',\n",
    "    'dataset_name': DATASET,\n",
    "    'operations': [\n",
    "        {'operation_name': 'mean', 'arguments': {'dim': None}},\n",
    "        {'operation_name': 'matmul'},\n",
    "        {'operation_name': 'sum'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "if SERVER:\n",
    "    try:\n",
    "        wf_resp = requests.post(f"{API}/api/v1/vector/tensor-workflow", json=workflow_payload, timeout=60)\n",
    "        wf_resp.raise_for_status()\n",
    "        workflow_result = wf_resp.json()\n",
    "    except requests.RequestException as exc:\n",
    "        workflow_result = {'error': str(exc), 'demo_mode': True}\n",
    "else:\n",
    "    workflow_result = {'demo_mode': True, 'workflow_id': 'demo_workflow', 'final_result': {'value': 123.4}}\n",
    "\n",
    "print(pretty_json(workflow_result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
